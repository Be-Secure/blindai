{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7-tQfVM_pJcr"
   },
   "source": [
    "<div id=\"colab_button\">\n",
    "  <h1>Under the hood</h1>\n",
    "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/mithril-security/blindai/blob/main/docs/docs/getting-started/under-the-hood.ipynb\"> \n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nitro enclaves with BlindAI API: Under the hood\n",
    "___________________________________________\n",
    "\n",
    "In the quick tour, we saw how we can use the BlindAI Whisper API to query the Whisper model with data protected during computation by a Nitro enclave environment.\n",
    "\n",
    "Let's take a look at what is going on under the hood when we use the Whisper API."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying the BlindAI Nitro Enclave server\n",
    "___________________________________________\n",
    "\n",
    "When you use our Whisper API with Nitro enclaves, by default, you connect to the BlindAI Nitro server hosted by Mithril Security. The advantage of this is that it allows you to test our APIs for free and without spending any time on deployment.\n",
    "\n",
    "Nitro Enclaves are an AWS technology and can be deployed on Amazon EC2 instances only. Our BlindAI server for Nitro enclaves is deployed on an [Amazon EC2 R6i Instance](https://aws.amazon.com/ec2/instance-types/r6i/).\n",
    "\n",
    "If you want to deploy your own BlindAI API server for Nitro enclaves, check out our guide on how to do this [here]."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " when we query a model hosted using Nitro enclaves using the BlindAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "\n",
    "import requests\n",
    "\n",
    "res = requests.post(\n",
    "    \"https://nitro.mithrilsecurity.io/whisper/predict\",\n",
    "    files={\n",
    "        \"audio\": open(\"test2.wav\", \"rb\"),\n",
    "    },\n",
    ").text\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We send our audio file and the query request to the verified Mithril server using a secure TLS communication channel and get back our resulting transcribed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install AWS CLI\n",
    "!curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "!unzip awscliv2.zip\n",
    "!sudo ./aws/install\n",
    "\n",
    "# check it is now installed\n",
    "!aws --version\n",
    "\n",
    "# install terraform\n",
    "!wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg\n",
    "!echo \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/hashicorp.list\n",
    "!sudo apt update && sudo apt install terraform\n",
    "\n",
    "# check it is now installed \n",
    "!terraform --version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will need to export your AWS credentials in the environment you are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export AWS_SECRET_ACCESS_KEY=[YOUR_AWS_SECRET_ACCESS_KEY_HERE]\n",
    "# !export AWS_ACCESS_KEY=YOUR_AWS_ACCESS_KEY_HERE]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now we are ready to deploy our BlindAI server. Before starting, we can check our AWS instance dashboard and see we have no instances currently running\n",
    "\n",
    "![AWS empty dashboard](../../assets/no-instance-running.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then clone the BlindAI Nitro enclave repo and deploy the server using `terraform apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone \"https://github.com/mithril-security/whisper-fastapi\"\n",
    "# !cd whisper-fastapi\n",
    "# !terraform apply"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terraform will produce some output in the terminal confirming the resources that will be allocated to us. \n",
    "\n",
    "You will notice in the details of these resources that `enclave_options`: `enabled` is set to `true`.\n",
    "\n",
    "You must select `yes` to confirm the allocation of these resources.\n",
    "\n",
    "Terraform then runs our start script to deploy our BlindAI API application on the server instance.\n",
    "\n",
    "Now when we check out our instance dashboard on our AWS account, we can see our BlindAI Nitro server instance is now running:\n",
    "\n",
    "![Nitro server running on AWS](../../assets/Nitro-server-running.png)\n",
    "\n",
    ">You can now get shell access to the application's host machine on port 22. You CANNOT get shell access to the enclave for security reasons.\n",
    "\n",
    ">You can send requests directly to the enclave, as seen in the previous section, on port 443."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "_________________\n",
    "\n",
    "In this quick-tour, we have:\n",
    "- Been introduced to the BlindAI API and seen how we can use the API to query the Whisper model.\n",
    "- Discovered how queries are performed under the hood.\n",
    "- Seen how you can deploy your own BlindAI server.\n",
    "\n",
    "## Coming soon\n",
    "\n",
    "We hope you'll enjoy testing out our BlindAI API models with Nitro Enclave and Intel SGX TEEs! \n",
    "\n",
    "Meanwhile, we are busy preparing for our next step, the release of our **BlindBox** solution, allowing developers to deploy not just **the BlindAI servers**, but ANY compatible application server, within a secure enclave!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9dLZ16T528YV"
   },
   "source": [
    "## Community\n",
    "_________________\n",
    "\n",
    "Ask questions on our [**Github**](https://github.com/mithril-security/blindai/issues) or on our [**Discord**](https://discord.com/invite/TxEHagpWd4). We love feedback!ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "blindai-preview-7Yaoi9am-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
