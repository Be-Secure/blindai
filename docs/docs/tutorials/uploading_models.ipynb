{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"colab_button\">\n",
    "  <h1>Uploading models with BlindAI</h1>\n",
    "  <a target=\"_blank\" href=\"LINK\"> \n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "</div>\n",
    "\n",
    "_____________________________________________________________________\n",
    "\n",
    "One of the first steps for AI engineers using BlindAI to serve their models with privacy guarantees is to upload their models to their BlindAI server instance. This can be done using our easy-to-use Python API, but first, your models need to be converted to the Open Neural Network Exchange Format (ONNX) format.\n",
    "\n",
    "ONNX is a standard enabling framework interoperability, allowing you to easily move models between different machine learning libraries.\n",
    "\n",
    "In this tutorial, we will show you how to take models from three of the most popular ML libraries, `PyTorch`, `TensorFlow` and `HuggingFace`, convert them to ONNX format, and upload them to BlindAI.\n",
    "\n",
    "So, let's dive in.\n",
    "\n",
    "## Pre Requisites\n",
    "_______________________________________\n",
    "\n",
    "### Installing required dependencies\n",
    "\n",
    "Unless you're are running this notebook on Google Colab, you'll need to have [`Python`](https://www.python.org/downloads/) (3.8 or greater) and [`pip`](https://pypi.org/project/pip/) installed to run this notebook.\n",
    "\n",
    "Then, you'll need to install the BlindAI-preview package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install blindai-preview package\n",
    "!pip install blindai-preview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need to install some additional dependencies for this notebook:\n",
    "\n",
    "- [`torch`](https://pytorch.org/): to demo ONNX conversion for PyTorch models\n",
    "- [`tensorflow`](https://www.tensorflow.org/): to demo ONNX conversion for TensorFlow models\n",
    "- [`transformers`](https://huggingface.co/): to demo ONNX conversion for HuggingFace models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install all other required packages\n",
    "!pip install torch tensorflow transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the BlindAI server\n",
    "\n",
    "Before we can upload any models, we will first need to launch an instance of BlindAI's server. \n",
    "\n",
    "For the purposes of this tutorial, we will use the `blindai_preview.testing` server which has been designed for testing purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import testing submodule\n",
    "import blindai_preview.testing\n",
    "\n",
    "# start the server\n",
    "srv = blindai_preview.testing.start_mock_server()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note that the blindai-preview testing module launches the server in simulation mode. As a result, it doesn't provide hardware protection and **must not be used in production**. We created this option to enable users to quickly and easily test BlindAI without needing to run the server on a machine with Intel SGX hardware. To learn more about how to run the server with hardware protections on, see [our documentation](https://blindai-preview.mithrilsecurity.io/en/latest/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: Download model\n",
    "\n",
    "We will use the pretrained `resnet18` image-classifying neural network as our example model for this section. \n",
    "\n",
    "The first step is to download the model from `PyTorch Hub`. We do this using the `hub` module's `load` method. \n",
    "\n",
    "The first argument we provide specifies the Github repo and directory where the model can be installed from. We then specify the name of the model to be downloaded and set the `pretrained` option to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to call `model.eval()` or `model.train(False)` before exporting the model to ensure the model is set to inference mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: ONNX conversion\n",
    "\n",
    "We will use the `torch.onnx.export()` function to convert our model to ONNX fomat.\n",
    "\n",
    "The `export` method will execute the model, recording a trace of what operators are used to compute the outputs. To do this, we need to supply it with some dummy inputs in the shape the model would expect. \n",
    "\n",
    "For resnet18, the dummy input should be in the following format: `batch size`, `channel width`, `image size`, `image size`.\n",
    "\n",
    "The values we provide for each dimension will be fixed in the exported ONNX graph, meaning all future input must match this shape. There is a way around this however, by specifying axes as a dynamic axes.\n",
    "\n",
    "Let's create our dummy input now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy inputs for resnet18 model\n",
    "dummy_inputs = torch.zeros(1,3,224,224)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The channel width should be 3, representing the RGB values of our image, and the image size should be 224-by-224. \n",
    "\n",
    "We will set the `batch_size` to 1, but then specify the first dimension as dynamic with the `dynamic_axes` option.\n",
    "\n",
    "Since the values used for our dummy input are not important- here, we will fill our dummy input with zeros.\n",
    "\n",
    "Now that we have created our dummy inputs, we are ready to call the `onnx.export()` method. We pass the method our PyTorch model, the dummy inputs, the name we want to give our ONNX file and finally any dynamic axes for input and output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, dummy_inputs, \n",
    "                \"resnet18.onnx\", \n",
    "                dynamic_axes={'input' : {0 : 'batch_size'}, 'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For information about more export options, see the `torch.onnx.export` [documentation](https://pytorch.org/docs/stable/onnx.html#torch.onnx.export).\n",
    "\n",
    "We have now successfully converted our PyTorch model ready to be uploading to the server."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading model\n",
    "\n",
    "Before we can upload the model, we need to connect to the server using BlindAI's `connect()` function.\n",
    "\n",
    "Since we are using a server in `simulation` mode, we need to set the `simulation_mode` parameter to `True` on the client side also. This is needed because the client will refuse to connect to an unsecure server otherwise.  \n",
    "\n",
    ">Note, we also set the `hazmat_http_on_unattested_port` option to `True`. By default, the `blindai_preview` package requires a HTTPS connection for communications between the client and server on the unattested port 9923. But for testing purposes we opt out of this requirement and connect without a secure connection. This should not be done in production, please refer to our documentation to set up a production server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blindai_preview \n",
    "# import blindai_preview\n",
    "\n",
    "# AI company connects\n",
    "client_1 = blindai_preview.connect(addr=\"localhost\", simulation_mode=True, hazmat_http_on_untrusted_port=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For the purposes of this demo, we are running the server on localhost using the default ports, but note that the host and ports are modifiable parameters in the `connect()` function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now go ahead and upload the model using the client `upload_model()` method, specifying the ONNX model's file name via the `model` parameter.\n",
    "\n",
    "We can store and print out our `model_id`, which is used to identify the model when running or deleting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI company uploads model to server\n",
    "response = client_1.upload_model(model=\"./resnet18.onnx\")\n",
    "MODEL_ID = response.model_id\n",
    "print(MODEL_ID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyTorch model has now been successfully uploaded to the BlindAI server and is ready to be consumed by users."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow: Download model and ONNX conversion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace: Download model and ONNX convert"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now uploaded and we have a `model_id` we can share with our client. \n",
    "\n",
    "We, PixelHealth, can now close our connection to the server using the `close()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disconnect from sever\n",
    "client_1.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "____________________________________\n",
    "\n",
    "This is the end of our introduction to BlindAI! \n",
    "\n",
    "We have seen how to:\n",
    "\n",
    "* **Connect** and **disconnect** to the BlindAI server.\n",
    "* **Upload**, **run** and **delete** models.\n",
    "* **Prepare** image data for the Covid-Net model.\n",
    "\n",
    "Please check out the rest of our [BlindAI documentation](https://blindai-preview.mithrilsecurity.io/en/latest/) to see more examples of how you can use BlindAI to deploy AI models without compromising the safety of user data or models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
